\documentclass{VUMIFPSkursinis}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{bm}
\usepackage{caption}
\usepackage{color}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{subfig}
\usepackage{wrapfig}
% \usepackage{lithuanian}
\usepackage{longtable}
\usepackage{xcolor}


\usepackage{enumitem}
%PAKEISTA, tarpai tarp sąrašo elementų
\setitemize{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}
\setenumerate{noitemsep,topsep=0pt,parsep=0pt,partopsep=0pt}

% Titulinio aprašas
\university{Vilniaus universitetas}
\faculty{Matematikos ir informatikos fakultetas}
\department{Programų sistemų katedra}
\papertype{Kursinis darbas}
\title{Rodiklių duomenų kaupimas, transformavimas ir analizė, naudojant srautinį duomenų apdorojimą}
\titleineng{Indicator Data Collection, Transformation and Analysis Using Stream Processing}
\status{3 kurso 5 grupės studentas}
\author{Vytautas Žilinas}
\supervisor{lekt. Andrius Adamonis}
\date{Vilnius – \the\year}

% Nustatymai
% \setmainfont{Palemonas}   % Pakeisti teksto šriftą į Palemonas (turi būti įdiegtas sistemoje)
%\bibliography{bibliografija}
%\documentclass{article}
\usepackage[backend=biber]{biblatex}
\addbibresource{bibliografija.bib}
\begin{document}
	
% PAKEISTA	
\maketitle
\cleardoublepage\pagenumbering{arabic}
\setcounter{page}{2}

%TURINYS
\tableofcontents

\sectionnonum{Įvadas}

    Šiame darbe rodiklių duomenis laikysime didelių duomenų tipu, kur duomenis galime transformuoti ir analizuoti ir sugrupuoti pagal rodiklius, 
pavyzdžiui: bazinė mėnesio alga, mirusiųjų skaičius pagal mirties priežastis, krituliai per metus. Šie duomenys yra saugomi reliacinėse duomenų bazėse, 
kur užklausus vartotojui apdorojami ir grąžinami.\par
Lietuvoje rodiklių duomenų bazės pavyzdys yra ,,Lietuvos statistikos departamento" duomenų bazė, kurioje užklausas galima vykdyti
\url{https://osp.stat.gov.lt/statistiniu-rodikliu-analize#/} puslapyje, kuris leidžia ieškoti duomenis apdorotus pagal vieną arba kelis rodiklius. 
Kitas pavyzdys yra ,,DataBank" \url{http://databank.worldbank.org} - pasaulinio lygio rodiklių duomenų bazių rinkinys, turintis 69 skirtingas 
duomenų bazes, pavyzdžiui - ,,World development indicators", ,,Gander statistics"\cite{databank-stats}. \par
Šiuo metu pasaulyje yra aktuali didelių duomenų (angl. Big data) tema, kuri yra susijusi su tokiais iššūkiais kaip didelių duomenų kiekių saugojimas, 
transformacija, analizė. Rodiklių duomenims galime pritaikyti dalį didelių duomenų charakteristikų 
ir apsibrėžti, kurios iš jų mums sukelia daugiausiai iššūkių. Didelių duomenų iššūkiai yra apibrėžti Gartner's Doug Laney pristatytu 3V modeliu\cite{laney20013d},
kuris vėliau buvo papildytas Bernard Marr iki 5V modelio\cite{marr2014big}:
\begin{itemize}
    \item Tūris (angl. Volume). Apibrėžia generuojamų duomenų kiekius. Didelių duomenų atveju yra šnekama apie duomenų kiekius, kuriuos yra sudėtinga arba neįmanoma saugoti 
    ir analizuoti tradicinėmis duomenų bazių technologijomis. Rodiklių duomenų kiekiai nesudaro problemos saugojant, tačiau problema yra rodiklių duomenų analizė, 
    kadangi tuos pačius duomenis reikia apdoroti pagal neribotą kiekį skirtingų rodiklių.
    \item Greitis (angl. Velocity). Apibrėžia greitį, kuriuo nauji duomenys yra generuojami. Rodiklių duomenų atveju, tai yra svarbu, kadangi nauji duomenys, kurie gali 
    tikti skirtingiems rodikliams, yra generuojami pastoviai.
    \item Įvairovė (angl. Variety). Apibrėžia duomenų tipus. Duomenys gali būti: struktūrizuoti, nestruktūrizuoti arba dalinai struktūrizuoti\cite{zikopoulos2011understanding}. 
    Rodiklių duomenys yra struktūrizuoti, todėl tai nėra aktualus iššūkis.
    \item Tikrumas (angl. Veracity). Apibrėžia duomenų teisingumą ir kokybę. Pavyzdžiui, jeigu analizuotume ,,Twitter" socialinio tinklo žinučių turinį gautume daug gramatikos klaidų, naujadarų, slengo. 
    Statistinio departamento atveju duomenys visada, kiek įmanoma, bus tvarkingi, kadangi tai yra duomenys surinkti iš dokumentų ir apklausų, o ne laisvai įvedami.
    \item Vertė (angl. Value). Apibrėžia duomenų ekonominę vertę. Rodiklių duomenys yra vertingi įstaigoms, nes tos įstaigos užsiima tik rodiklių duomenų kaupimų ir analizė, iš techninės pusės
    ši charakteristika yra svarbi iš tos pusės, kad duomenų apdorojimo ir kaupimo sprendimai daro įtaką įstaigos, kaupiančios rodiklių duomenis, veiklai. 
    Todėl šie apdoroti duomenis turi būti pasiekiami be prastovos laiko.
\end{itemize}\par

Darbo tikslas: Eksperimento būdu išbandyti rodiklių duomenų kaupimo, transformavimo ir analizės uždavinių sprendinius, 
palyginant sprendimą, naudojanti reliacinę duomenų bazę, su sprendimu naudojančiu srautinį duomenų apdorojimą. \par

Užduotys:
\begin{enumerate}
    \item Atlikti skirtingų srautinio duomenų apdorojimo sprendimo architektūrų analizę, ir pasirinkti vieną iš jų tyrimui.
    \item Sukurti testavimo duomenų generatorių.
    \item Išmatuoti sukurto reliacinės duomenų bazės sprendimo pralaidumą.
    \item Realizuoti srautinio duomenų apdorojimo architektūros rodiklių duomenų kaupimo sprendimą.
    \item Išmatuoti srautinio duomenų apdorojimo sprendimo pralaidumą ir palyginti testavimo rezultatus.
\end{enumerate}

Eksperimento metu testuojami sprendimai bus vykdomi ne su tikrais rodiklių duomenimis, o su supaprastinto uždavinio sugeneruotais duomenimis.

\section{Duomenų apdorojimo tipai}

\subsection{Srautinis duomenų apdorojimas} \label{strprocess}

    Srautinis duomenų apdorojimas (angl. Stream processing) - yra programavimo paradigma ekvivalenti anksčiau aprašytai duomenų tėkmės programavimo (angl. dataflow programming) paradigmai\cite{shortstreamproc}. 
Duomenų tėkmės programavimo paradigmos idėja, kad visa programa susidaro iš skirtingu modulių, kurie nepriklauso vienas nuo kito ir būtent tai leidžia sukonstruoti paraleliai skaičiuojančias programas. 
Viena iš pirmųjų duomenų tėkmės programavimo kompiliatorių yra BLODI - blokų diagramų kompiliatorius (angl. BLOck DIagram compiler), su kuriuo buvo kompiliuojamos BLODI programavimo kalba parašytos programos. 
Šia kalba parašytos programos atitinka inžinierinę elektros grandinės schemą, kur duomenys keliauja per komponentus kaip ir elektros grandinėje. Vienas iš šios programavimo kalbos privalumų buvo tai, 
kad ją galėjo išmokti žmonės, kurie nebuvo programavimo ekspertai\cite{kelly1961block}.\par
Kad apžvelgti modernias srautinio duomenų apdorojimo architektūras reikia apsibrėžti srautinio apdorojimo sistemų galimybes.
2005 metais Michael Stonebraker apibrėžė 8 taisyklės realaus-laiko srautinio duomenų apdorojimo architektūroms\cite{stonebraker20058}:
\begin{enumerate}[label=\arabic*]
    \item taisyklė: Duomenys turi judėti. Kad būtų užtikrinta žemas uždelsdamas sistema turi apdoroti duomenis nenaudojant duomenų saugojimo operacijas. Taip pat sistema turi ne pati užklausti duomenų, o gauti juos
    iš kito šaltinio automatiškai. 
    \item taisyklė: Duomenų transformacijos turi būti vykdomas SQL pobūdžio užklausomis. Žemo lygio srautinio apdorojimo sistemos reikalauja ilgesnio programavimo laiko ir brangesnio palaikymo. Tuo tarpu aukšto lygio sistema 
    naudojanti SQL užklausas, kurias žino dauguma programuotojų ir naudojama daug skirtingų sistemų, leidžia efektyviau kurti srautinio apdorojimo sprendimus.
    \item taisyklė: Architektūra turi susidoroti su duomenų netobulumais. Architektūra turi palaikyti galimybę nutraukti individualius skaičiavimus, tam kad neatsirastų blokuojančių operacijų. Taip pat ši 
    architektūra turi sugebėti susidoroti su vėluojančiomis žinutėmis, pratęsiant laiko tarpą per kurį tą žinutė turi ateiti.
    \item taisyklė: Architektūra turi generuoti nuspėjamus rezultatus. Kiekvieną kartą apdorojant tuos pačius duomenis rezultatai turi būti gaunami tokie patys.
    \item taisyklė: Architektūra turi gebėti apdoroti išsaugotus duomenis ir realiu laiku gaunamus duomenis. Sistema parašyta su tokia architektūra turi galėti apdoroti jau esančius duomenis taip pat kaip ir 
    naujai ateinančius. Toks reikalavimas atsirado, nes reikėjo galimybės nepastebimai perjungti apdorojimą iš istorinių duomenų į gyvus realiu laiku ateinančius duomenis automatiškai.
    \item taisyklė: Architektūra turi užtikrinti duomenų saugumą ir apdorojimo prieinamumą. Kadangi sistema turi apdoroti didelius kiekius duomenų, architektūra, klaidos atveju, turi sugebėti persijungti į atsarginę
    sistemą ir tęsti darbą toliau. Taip pat tokios klaidos atveju atsarginė sistema turi būti apdorojusi visus duomenis ir sugebėti iš karto priimti naujus duomenis, o ne apdoroti duomenis iš pradžių.
    \item taisyklė: Architektūra turi užtikrinti sugebėjimą paskirstyti sistemos darbus automatiškai. Srautinio apdorojimo sistemos turi palaikyti kelių procesoriaus gijų operacijas. Taip pat sistema turi galėti 
    veikti ant kelių kompiuterių vienu metu ir prireikus paskirstyti resursus pagal galimybes.
    \item taisyklė: Architektūra turi apdoroti ir atsakyti momentaliai. Anksčiau minėtos taisyklės nėra svarbius, jeigu sistema nesugeba greitai susidoroti su dideliu kiekiu naujų duomenų. Kad tai sistema
    pasiektu turi būti naudojamas ne tik teisingas ir greitas srautinio apdorojimo sprendimas, bet ir gerai optimizuota sistema.
\end{enumerate}\par
        Šie reikalavimai yra sukurti tik teoriškai ir egzistuoja labai nedaug srautinio apdorojimo architektūrų atitinkančių visas šias taisykles. Tam kad išsirinkti tinkamą architektūrą sprendžiamam uždaviniui, 
        konkrečios srautinio apdorojimo architektūros yra apžvelgiamos ir lyginamos \ref{srautarch} skyriuje.

\subsection{Paketinis duomenų apdorojimas}
    Paketinis duomenų apdorojimas (angl. Batch processing) - yra duomenų apdorojimo paradigma, kai duomenys yra saugomi saugykloje, o vėliau, po užklausos, apdorojami.
    Vienas iš tokio apdorojimo sistemų pavyzdžių būtent ir yra reliacinė duomenų bazė. Reliacinės duomenų bazių valdymo sistemos (angl. Relational database management systems) - tai 
    duomenų valdymo sistema paremta reliaciniu modeliu pirmą kartą aprašytu 1969 metais\cite{codd1969derivability}.
    Pagal \url{https://db-engines.com/en/ranking} 2018 metų birželio mėnesio rodiklius šiuo metu pagal populiarumą tarp reliacinių ir NoSQL duomenų bazių sistemų pirmos 5 vietos iš 343 yra paskirstytos atitinkamai:
    \begin{enumerate}
        \item Oracle (Reliacinė DBVS) - 1311.25
        \item MySQL (Reliacinė DBVS) - 1233.69
        \item Micorsoft SQL Server (Reliacinė DBVS) - 1087.73
        \item PostgreSQL (Reliacinė DBVS) - 410.67
        \item MongoDB (NoSQL DBVS paremta dokumentų saugyklos modeliu) - 343.79
    \end{enumerate}\par
        Šie rezultatai yra apskaičiuojami pagal ,,DB-engines" algoritmą, kuris atsižvelgia į sistemų paminėjimus svetainėse, paieškos dažnį paieškos varikliuose, techninių diskusijų kiekį
       žinomose su informacinėmis technologijomis susijusiose svetainėse, profesionalių tinklų profiliuose, populiarumą socialiniuose tinkluose\cite{dbengines}. Aiškiai matome, kad reliacinės
    duomenų bazių valdymo sistemos stipriai lenkia, bet kokias kitas saugyklas. Būtent toks populiarumas ir lemia, kad jos yra naudojamos ir duomenų apdorojimui. Kadangi reliacinė
    duomenų bazė jau egzistuoja, reiškia įmonei nereikia leisti papildomų lėšų: išanalizuoti kitokios sistemos tinkamumą užduočiai, sukurti sprendimą, palaikyti naują sistemą, 
    pasisamdyti naują žmogų mokanti dirbti su šia sistema arba apmokyti esamą. \par
        Reliacinių duomenų bazių duomenų apdorojimo būdas yra Procedūros(angl. stored procedures), kurios aprašomos SQL kalba ir gali apdoroti duomenis tiesiai iš duomenų bazės 
    naudojant reliacinę matematiką. Tačiau jeigu pažiūrėsimi į procedūrą, kaip duomenų apdorojimo architektūrą pagal \ref{strprocess} skyriuje apibrėžtas 8 taisykles, 
    matysime, kad ji neatitinką: 1-os taisyklės: Duomenys turi judėti. Procedūros yra leidžiamos tik vartotojui užklausus, todėl šis reikalavimas yra neišpildytas, 
    ir 7-os taisyklės: Architektūra turi užtikrinti sugebėjimą paskirstyti sistemos darbus automatiškai. Didžioji dalis reliacinių duomenų bazių nepalaiko horizontalų 
    plečiamumą\cite{cattelsql, jkubas} ir todėl viena sistema gali apdoroti tik pas ją esančius duomenis. Svarbiausiai, procedūra negali apdoroti greitai naujų duomenų jeigu duomenų bazėje 
    jau yra didelis kiekis duomenų, kuriuos reikia apdoroti, nes procedūra apdoroja ne tik naujus bet visus duomenis, tai pažeisdama 8-tą duomenų apdorojimo taisyklė,
    ir ko pasėkoje reliacinis sprendimas analitiškai yra mažiau tinkamas rodiklių duomenų problemai.


\section{Srautinio duomenų apdorojimo architektūrų sprendimų ypatumai} \label{srautarch}
Šiame skyriuje palyginsime tris atviro kodo srautinio apdorojimo architektūras ,,Apache Storm", ,,Apache Spark" ir ,,Apache Flink" pagal:
\begin{itemize}
    \item Pristatymo semantika (angl. delivery semantics) - apibrėžia pagal kokį modelį bus pristatyti duomenys. Egzistuoja trys semantikos\cite{ensar20}: 
    \begin{itemize}
        \item Bent vieną kartą (angl. At-least-once) užtikrina, kad duomenys bus apdoroti bent kartą, bet gali atsirasti dublikatų. 
        \item Ne daugiau vieno karto (angl. At-most-once) užtikrina, kad duomenys bus apdoroti daugiausiai tik vieną kartą, bet gali atsirasti praradimų. 
        \item Tiksliai vieną kartą (angl. Exactly-once) užtikrina, kad duomenys bus apdoroti tik vieną kartą net ir atsiradus klaidoms.
    \end{itemize}
    \item Uždelstumas (angl. Latency) - apibrėžia kiek laiko užtruks įvykdyti kažkokį veiksmą arba gauti rezultatą.
    \item Pralaidumas (angl. Throughput) - apibrėžia kiek pavyks įvykdyti operacijų per tam tikrą laiko tarpą.
    \item Abstrakcijos lygis (angl. Abstraction) - apibrėžia kokio lygio programavimo sąsają pateikia architektūra.
\end{itemize}

\subsection{Pristatymo semantika}
,,Apache Spark" ir ,,Apache Storm" architektūrų pristatymo semantika yra tiksliai vieną kartą (angl. Exactly-once), tai reiškia, kad visi 
duomenys bus apdoroti tik vieną kartą. Tačiau tam, kad užtikrinti šią semantiką architektūra sunaudoja daug resursų, nes reikia užtikrinti, kad 
operacija bus vykdoma būtent vieną kartą kiekviename srautinio apdorojimo žingsnyje: duomenų gavime, kas stipriai priklauso nuo duomenų šaltinio,
duomenų transformacijos, kuri turi užtikrinti pati srautinio apdorojimo architektūra ir duomenų saugojime, kas turi būti užtikrinta architektūros ir
naudojamos saugyklos\cite{zhang20}.\par
    ,,Apache Storm" pristatymo semantika yra bent viena kartą (angl. at-least-once), kas reiškia, kad per šią architektūra leidžiami duomenys 
visada pasieks pabaigą, tačiau kartais gali dubliuotis\cite{prithi20}. Jeigu sprendimas reikalauja tiksliai vieno karto apdorojimo, tada mes turime rinktis arba vieną 
iš aukščiau minėtų architektūrų arba ,,Apache Storm Trident" - ant ,,Apache storm" architektūros pastatyta aukšto abstrakcijos lygio architektūra 
galinti užtikrinti tiksliai vieno karto apdorojimą. Tačiau jei uždavinys to nereikalauja, greičio, ypač uždelstume, atveju daug geriau pasirinkti 
pigesnę pristatymo semantiką\cite{zhang20}.
\subsection{Uždelstumas}
    Uždelstumas, srautinio apdorojimo architektūroms yra matuojamas milisekundėmis, kas parodo kaip greitai architektūra įvykdo vieną operaciją. 
Pagal Martin Andreoni Lopez darytus bandymus su šiomis architektūromis galime matyti, kad būtent ,,Apache Storm" turi mažiausią uždelstumą,
parinkus teisingai paralelizmo parametrą ši architektūra su užduotimi susidorojo net iki 15 kartų greičiau. Antroje vietoje liko ,,Apache Flink", o po jos
,,Apache Spark"\cite{Lopez2016APC}. Tačiau kai architektūra turi žemą uždelstumą, tai ji turės taip pat ir žemą pralaidumą, kas nėra gerai, 
kai norima apdoroti daug duomenų iš karto.

\subsection{Pralaidumas}
    Pralaidumas apibrėžia kokį kiekį procesų sistema gali įvykdyti per tam tikrą laiko tarpą. 2016 metais Sanket Chintapalli su kolegomis išmatavo ,,Apache Storm",
,,Apache Spark" ir ,,Apache Flink" architektūrų pralaidumą ir uždelstumą ir palygino rezultatus. Kaip ir anksčiau manyta, ,,Apache Spark" turėjo aukščiausia 
pralaidumą iš visų, kadangi jis vienintelis iš trijų duomenis apdoroja mikro-paketais. Antroje vietoje liko ,,Apache Flink", kuris yra subalansuotas,
pralaidumo atveju ir paskutinis liko ,,Apache Storm", kuris turi žemą uždelstumą, todėl nukenčia pralaidumas\cite{chintapalli2016benchmarking}.
\subsection{Abstrakcijos lygis}

,,Apache Storm" parašytos programos yra žemo lygio abstrakcijos. 
Kadangi tai yra žemo lygio programa mes turime apsirašyti visus srauto apdorojimo modulius, 
tai yra: setSpouts(..), kur nustatoma duomenų įeiga ir koks bus paralelizmas lygis, setBolt(..), kur nustatomi apdorojimo moduliai,
kokius duomenis gaus iš prieš tai buvusio modulio ir paralelizmo lygis. Kiekvieno modulio execute() metodas aprašo, kaip šis modulis 
turi apdoroti duomenis\cite{tutpoint}. Šios architektūros programų kūrimo laikas užtruks ilgiau negu kitoms architektūroms su aukštu abstrakcijos lygių,
tačiau žemas abstrakcijos leidžia rašyti daug greičiau veikiančias programas, kadangi programuotojas turi pilną kontrolę.

,,Apache Spark" parašytos programos yra aukšto lygio abstrakcijos. 
Programa aprašoma funkciškai, todėl kodo rašymas trunka daug trumpiau ir tokį kodą daug patogiau skaityti. Tačiau prarandama galimybė optimizuoti
ir paralelizmo klausimas paliekamas architektūrai. Kadangi ,,Apache Spark" yra ne pilnai srautinio, o mikro-paketinė (angl. micro-batching) 
architektūra, todėl vartotojas turi apsirašyti kokio dydžio paketais bus renkami duomenys \cite{shoro2015big}.

,,Apache Flink" parašytos programos yra aukšto lygio abstrakcijos. ,,Apache Flink" 
architektūra pati užsiima resursų distribucija, todėl programuotojui lieka tik parašyti veikianti kodą, o sistema pati susitvarkys su paralelizmu\cite{flinkdoc}. Tačiau 
tai reiškia, kad su šia architektūra parašytos programos nepavyks optimizuoti taip pat gerai kaip žemo lygio abstrakcijos architektūros.

\subsection{Apibendrinimas}
Iš šių trijų architektūrų reikia pasirinkti vieną, kuri labiausiai tiks rodiklių duomenų apdorojimui. Ši architektūra turi sugebėti greitai apdoroti duomenis,
prioretizuojant greiti virš tikslumo, kadangi vienas iš pagrindinių naudotojų yra statistiką renkančios įstaigos, kurios gali sau leisti tam tikrą paklaidą,
ir programuotojas turi galėti aprašyti daug skirtingų sprendimų skirtingiems rodikliams.\par

\begin{table}[!htbp]
    \begin{center}
        \caption{Srautinių architektūrų palyginimas}
        \label{table:comparer}
        \begin{tabular}{ | l | c | c | c | } 
            \hline
            Charakteristika & ,,Apache Storm" & ,,Apache Spark" & ,,Apache Flink" \\* \hline
            Pristatymo semantika & Bent vieną kartą & Tiksliai vieną kartą & Tiksliai vieną kartą \\* \hline
            Uždelstumas & Žemas & Aukštas & Vidutinis \\* \hline
            Pralaidumas & Žemas & Aukštas & Vidutinis \\* \hline
            Abstrakcijos lygis & Žemas & Aukštas & Aukštas \\* \hline
        \end{tabular}
    \end{center}
\end{table}\par

Kaip matome iš atliktos analizės \ref{table:comparer} lentelėje ir apsibrėžtų reikalavimų, mums labiausiai tinkanti srautinio apdorojimo architektūra yra ,,Apache Storm". 
Nors jos pralaidumas yra žemas, mums daug aktualiau yra greitis, taip pat žemas abstrakcijos lygis leis daug geriau optimizuoti sprendimą su šia architektūra. Su ją kursime
sprendimą, kurį lyginsime su reliacinės duomenų bazės sprendimu.

\section{Eksperimentinė sistema}

Eksperimentui buvo sukurta supaprastinta uždavinio versija tam, kad būtų galima palyginti reliacinės duomenų bazės sprendimo ir srautinio duomenų 
apdorojimo sprendimo greitaveikas (\ref{fig:architecture} pav.).
Šis eksperimentas yra aktualus tada, kai neapdorotų duomenų saugoti nereikia, o svarbi tik jų galutinė forma. Srautinio duomenų apdorojimo architektūra
išveda tik apdorotus duomenis, o reliacinė duomenų bazė duomenis turi saugoti atmintyje, kadangi šie duomenys vėliau turi būti apdoroti su sukurta 
procedūra. Eksperimento tikslas - išmatuoti ir palyginti abiejų sistemų greitaveiką, matuojant jų pralaidumą ir vieno naujo duomens apdorojimo laiką.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1\textwidth]{img/architecture.jpg}
    \caption{Eksperimentinės sistemos architektūra}
    \label{fig:architecture}
\end{figure}
\subsection{Eksperimento realizacija}


\subsubsection{Testavimo duomenų generavimo sprendimo realizacija}

Testavimo duomentų generavimo sistema yra sudaryta iš dviejų dalių: ,,Python" kalba parašytas duomenų generatorius ir siuntėjas į žinučių sistemą ir
,,Apache Kafka" žinučių sistema, kuri yra atsakinga už duomenų perdavimą iš generatoriaus į kitus modulius.\par
Su ,,Python" kalba parašytas duomenų generatorius, kuris sukuria nustatytą kiekį duomenų, naudojant ,,random" biblioteką ir, kai apibrėžtas kiekis duomenų sugeneruotas,
 po vieną siunčia į ,,Apache Kafka" žinučių sistemą, naudojant ,,kafka-python" biblioteką. Generuojami duomenys yra pritaikyti skirtingiems sprendimams.
Į srautinio apdorojimo sistemą siunčiami tik duomenys, kuriuos reikia apdoroti ir raktas pagal kurį apdoroti duomenys aggreguojami, o į reliacinės duomenų
bazės sprendimą siunčiami tik vienos iš lentelių pirminis raktas kuris parenkamas atsitiktiniai iš visų įmanomų, ir nauja duomenį. Duomenų siuntimas į 
žinučių sistemą vykdomas nepertraukiamai.  \par

,,Apache Kafka" - tai servisas gaunantis, saugojantis ir siunčiantis duomenis, kurie yra vadinami žinutėmis (angl. messages). Žinutės yra skirstomos pagal temas (angl. topics).
Yra žinučių kūrėjai (angl. producers), kurie siunčia žinutės į tam tikras temas, ir vartotojai (angl. consumers), kurie prenumeruoja (angl. subscribe)
prie temų, kad gautu su jomis susijusias žinutes\cite{thein2014apache}.  Taip pat visos žinutės šia sistema yra perduodamos tekstiniu formatu, 
tam kad bendrauti su ,,Apache Kafka" būtų įmanoma su bet kokia programavimo kalba. Bet dėl to nukenčia greitaveiką kadangi prisideda
papildomas darbas - konvertavimas iš teksto į reikiamą objektą.\par
%,,Apache Kafka" architektūra yra mums aktuali, nes ji laiko visas žinutes savo atmintyje, todėl tą pačią žinutę gali perskaityti keli vartotojai.
Ši testavimo duomenų generavimo sprendimas tinka srautinio apdorojimo sprendimams, kadangi jis siunčia žinutes,
kai tik gauna duomenis ir todėl duomenų apdorojimas gali vykti iš karto, o ne tada, kai sistema užklausia. Taip pat ,,Pyhton" programos sugeneruotus duomenis galime
be sunkūmų apdoroti su srautinio apdorojimo sprendimu, kuris yra parašytas bet kokia kita programavimo kalba. 
Mūsų sukurtas reliacinių duomenų bazės sprendimas taip pat naudoja ,,Apache Kafka". Nors ir reliacinės duomenų bazės sprendimo atžvilgiu, ši architektūra yra perteklinė, 
tačiau net pridėjus šį papildomą sluoksnį duomenų įrašymas sulėtėja nežymiai.\par

\subsubsection{Srautinio duomenų apdorojimo sprendimo realizacija}

,,Apache Storm" sistemai kuriama programa yra vadinama topologija (angl. topology), kuri susideda iš ,,Spout" ir ,,Bolt" modulių. ,,Spout" tai modulis gaunantis duomenis
iš išorinės sistemos ir perduodantis juos į pirmą ,,Bolt" modulį. ,,Bolt" yra atsakingi už duomenų apdorojimą ir atidavimą atgal į išorę.
Moduliai tarpusavyje perduoda duomenų ,,Tuple" tipu, kuris laiko duomenis ir architektūros sugeneruotą identifikatorių, 
kurio pagalba užtikrina, kad duomenys sėkmingai nuėjo iki sekančio žingsnio. 
Šiam uždaviniu spręsti buvo pasirinkta sukurti:
\begin{enumerate}
    \item ,,kafka-spout" - ,,Spout" modulis, kuris gauna duomenis iš ,,Apache Kafka" žinučių sistemos ir perduoda juos po jo einančiam ,,Bolt" moduliui.
    \item ,,calculate-price-bolt" - ,,Bolt" modulis, kuris gauna tekstinio tipo duomenis iš ,,kafka-spout" ir apdoroja vieną atejusį ,,Tuple".
    \item ,,aggregate-price-bolt" - ,,Bolt" modulis, kuris gauna apdorota ,,Tuple" iš ,,calculate-price-bolt" ir įdeda jį į ,,HashMap" tipo sąrašą ir visą sąrašą, 
    kas nustatytą laiko tarpą spausdina į tekstinį dokumentą.  
\end{enumerate}\par
Kadangi ,,Apache Storm" yra žemo lygio architektūra programuotojas turi pats numatyti paralelizmo lygi kiekviename modulyje. 
Po bandymų buvo nuspręsta modelių konfigūraciją daryti tokią: ,,kafka-spout" - 5 paralelus procesai, ,,calculate-price-bolt"
 - 5 paralelus procesai ir ,,aggregate-price-bolt" - 1 paralelus procesas. Paskutinį moduli negalima leisti paraleliai, nes jame saugomas bendras sąrašas,
kurio keitimas iš kelių gijų sugadina duomenis. Srautinio sprendimo greitaveika matuosime:
\begin{enumerate}
    \item Kiek duomenų srautinis sprendimas apdoroja per sekundę.
    \item Kiek užtrunka vieno duomens apdorojimas nuo duomens gavimo iš ,,Apache Kafka" serviso iki gauto duomens agregacijos į bendrą sarašą pabaigos.
\end{enumerate}

 \subsubsection{Reliacinės duomenų bazės sprendimo realizacija}

Reliacinės duomenų bazės realizavimui pasirinkta ,,Microsoft SQL Server" duomenų bazė, o duomenų apdorojimui parašyta procedūra (angl. stored procedure) ,,GetReports".
Sukurta minimali duomenų bazė, su 3 lentelėmis (\ref{fig:dbdiagram} pav.) Sukurta procedūra ,,GetReports" sujungia šias tris lenteles į vieną, kurioje yra parodoma kiekvienos 
parduotuvės (Shop) uždirbtus pinigus pagal nesudėtingą sumavimo formulę.
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=1\textwidth]{img/dbdiagram.jpg}
    \caption{Reliacinė duomenų bazė testavimui}
    \label{fig:dbdiagram}
\end{figure}
Kad duomenys iš generatoriaus patektų į duomenų bazę sukurta programa su ,,Python" kalba kuri gauna duomenis iš ,,Apache Kafka" žinučių sistemos ir talpina jas
duomenų bazėje, kiekviena gauta JSON užkoduota žinutė yra paverčiama į ,,Python" žodyno (angl. dictonary) tipą ir įdedama į įvedimo užklausą, kuri iškarto yra 
įvykdoma duomenų bazėje. Tokiu budu užtikrinamas nepertraukiamas duomenų įvedimas į reliacinė duomenų bazę.\par
Procedūros testavimui bus naudojama papildoma ,,Python" kalba parašyta programa, kuri gavusi žinutę iš ,,Apache Kafka" sistemos sukurs įdėjimo užklausą į duomenų bazę.
Taip pat ,,GetReports" procedūros iškvietimui yra naudojama ,,Pyhton" kalba parašyta programa, kuri periodiškai kviečia šią procedūrą. 
Kadangi mes negalime testuoti procedūros taip pat kaip srautinio apdorojimo sprendimą, mes darysime šį testą kitaip.
Vienų metų bus įvedami nauji duomenys ir tuo pačiu metu, su tam tikru laiko intervalu, kviečiama procedūra ir bus tikrinima:
    \begin{enumerate}
        \item Kiek duomenų per sekundę galima įdėti į duomenų bazę.
        \item Kiek sekundžių suletėja procedūra, kai yra pastoviai įvedami nauji duomenys.
    \end{enumerate}
\subsection{Eksperimento vykdymas}
Kompiuterio komponentų ir programų versijų su kuriais buvo vykdomas eksperimentas specifikacijos (\ref{table:hardware} lentelė).
\begin{table}[!htbp]
    \begin{center}
        \caption{Įrangos specifikacija}
        \label{table:hardware}
        \begin{tabular}{ | l | l |  } 
            \hline
            Procesorius & Intel i7-7700k 4,5 GHz \\* \hline
            Operatyvioji atmintis & 16 GB - 2666 Mhz \\* \hline
            Ilgalaikė atmintis & SSD 512 GB \\* \hline
            Operacinė sistema & Windows 10 64bit \\* \hline
            Reliacinė duomenų bazė & Windows SQL Server 14 \\* \hline
            Srautinio apdorojimo architektūra & Apache Storm 1.2.2 \\* \hline
            Žinučių sistema & Apache Kafka 1.1.0 \\* \hline
        \end{tabular}
    \end{center}
\end{table}\par

\subsubsection{Reliacinės duomenų bazės sprendimo eksperimento vykdymas}
Pradinėje duomenų bazėje egzistuoja 2,000 parduotuvių (Shop), kurios turi 0 arba daugiau prekių, 1,000,000 prekių (Product), kurios turi 0 arba daugiau pirkimų ir 10,000,000 pirkimų (Buys).
Prieš pradedant eksperimentą išmatuota, kiek užtrunka ,,GetReports" procedūra, neapkraunant duomenų bazės kitais veiksmais, ir per kiek laiko užtrunka visų duomenų įdėjimas,
nedarant kitų užklausų. 
Eksperimento eiga su reliacine duomenų baze atrodo taip:
\begin{enumerate} 
\item Paleidžiama ,,Python" programa gaunanti žinutes iš ,,Apache Kafka" žinučių sistemos ir įvedanti tuos duomenis į duomenų bazę. 
\item Paleidžiama programa kviečianti procedūrą ,,GetReports" ir nustatyta, kad ji procedūrą kviestų kas 5 sekundes norint simuliuoti realią apkrovą,
po kiekvieno kvietimo ji fiksuoja kiek laiko užtrūko ir kelintą kartą ji yra kviečiama. 
\item Paleidžiamas testavimo duomenų generatorius.
\end{enumerate}
\subsubsection{Srautinio duomenų apdorojimo sprendimo eksperimento vykdymas}

Prieš pradedant testavimą į sistemą buvo sugeneruoti 10,000,000 įrašų, kad būtų sudarytos sąlygos panašios kaip ir reliacinės duomenų bazės.
Šiai sistemai pagal nutylėjimą buvo išskirti 832 megabaitai operatyvios atminties (angl. RAM). 
Eksperimento eiga su srautinių duomenų apdorojimu atrodo taip:
\begin{enumerate} 
\item Paleidžiama ,,Apache Storm" sistema ir į ją užkraunama sukurta topologija.
\item Paleidžiamas testavimo duomenų generatorius.
\end{enumerate}
\newpage
\subsection{Eksperimento rezultatai}
\begin{table}[!htbp]
    \begin{center}
        \caption{Rezultatai}
        \label{table:results}
        \begin{tabular}{ | l | p{4cm} | p{3cm} | } 
            \hline
            Procesorius & Reliacinės duomenų bazės sprendimas & Srautinio apdorojimo sprendimas \\* \hline
            Pralaidumas (duomenų kiekis per sekundę) & \textasciitilde4,200 & \textasciitilde5,475 \\* \hline
            Vienos duomens apdorojimas ir agregacija & \textasciitilde75 milisekundės & \textasciitilde12 sekundžių \\* \hline
        \end{tabular}
    \end{center}
\end{table}\par
\subsubsection{Reliacinės duomenų bazės sprendimo eksperimento rezultatai}
Tiesiog kviečiant procedūrą ,,GetReports" trunka vidutiniškai 12 sekundžių. Kviečiant įdėjimo funkciją, be jokios kitos apkrovos ant duomenų bazės - 1,5 milijonų duomenų
buvo įdėti per 358 sekundžių, beveik 6 minutes. Tačiau paleidus tokį pat pastovų įrašų srautą į duomenų bazę ir bandant tuo pačiu metu gauti apdorotus duomenis,
procedūra užtruko vidutiniškai 29 sekundes ir taip pat apdorotas duomenų sąrašas po generavimo atsiliko virš 120,000 įrašų - tiek duomenų buvo įdėta procedūros veikimo metu. 
Per visą įdėjimo laiką procedūra ,,GetReports" buvo ivykdyta 10 kartų.
Taip pat vienas iš procedūros trūkumų - įdėjus bent vieną naują duomenį ir norint gauti ataskaitą turi iš naujo būti vykdoma procedūra, kurios trukmė, kai nėra 
paleista jokia kita užklausa, apie 12 sekundžių su testuojama duomenu imtimi.

\subsubsection{Srautinio duomenų apdorojimo sprendimo eksperimento rezultatai}
Paleista testavimo programa siunčianti 1,5 milijono duomenų neribojant siuntimo greičio, rezultatai buvo stebimi įrašais tekstiniame dokumente.
Visi, 1,5 milijonų, duomenų buvo apdoroti per 274 sekundes, kas yra maždaug 4,5 minutės. Vidutiniška vienos operacijos trukmė nuo 
patekimo į ,,Apache Kafka" žinučių sistemą iki galutinio pridėjimo prie bendro sąrašo - 75 milisekundės.
Lėčiausia sistemos grandis buvo ,,aggregate-price-bolt", nes jo negalima buvo leisti paraleliai. Šios sistemos veikimą pagreitinti 
įmanoma tik perdavus paskutinio moduliu agregavimą į sąrašą kitai architektūrai, kadangi visus kitus veiksmus galima leisti paraleliai.

\sectionnonum{Rezultatai ir išvados}

\textbf{Darbo rezultatai:}
\vspace{1 mm}

    \begin{enumerate}
        \item Sukurtas testavimo duomenų generatorius, sukurtas supaprastinto uždavinio sprendimas su reliacina duomenų baze ir su srautinio apdorojimo archiketūra.
        \item Uždavinio sprendimai palyginti pagal pralaidumo testų rezultatus.
    \end{enumerate}
    \vspace{1 mm}

\textbf{Išvados:}
\vspace{1 mm}

    \begin{enumerate}
    \item Eksperimento būdu pagrįsta, kad siūloma sistema gali būti įgyvendinama.
    \item Pralaidumo testavimo metu įrodyta, kad srautinio duomenų apdorojimo sprendimas apdoroja duomenis greičiau 
    (\textasciitilde75 milisekundės naujo duomens apdorojimui ir agregacijai į esamą sarašą) nei reliacinių duomenų
    bazės sprendimas (\textasciitilde12 sekundžių) ir nėra priklausomas nuo kitų tuo pačiu metu vykdomų procesų.
    \item Eksperimentui sukurtos sistemos srautinio duomenų apdorojimo sprendimo pralaidumas aukštesnis 
    (\textasciitilde5,475 duomenų per sekundę), negu reliacinės duomenų bazės (\textasciitilde 4,200 duomenų per sekundę). 
    \item Srautinio apdorojimo architektūra ,,Apache Storm" šiam uždaviniui užtikrina duomenų apdorojima milisekundžių greičiu.  

    \end{enumerate}

\printbibliography[heading=bibintoc] 

\end{document}
